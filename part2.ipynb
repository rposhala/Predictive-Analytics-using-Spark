{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : Using TF-IDF for feature engineering and model was built using Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('/home/cse587/spark-2.4.0-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "\n",
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .appName(\"Assignment3p2\") \\\n",
    "   .config(\"spark.some.config.option\", \"8gb\") \\\n",
    "   .getOrCreate()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlcontext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading necessary libraries for this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "import re\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import numpy as np\n",
    "from pyspark.ml.classification import LogisticRegression, OneVsRest\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.sql.functions import udf, col, lower, regexp_replace\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler, VectorIndexer, IndexToString\n",
    "from pyspark.mllib.linalg import SparseVector, DenseVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = pd.read_csv(\"/home/cse587/Project3/train.csv\",sep=\",\", header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_name</th>\n",
       "      <th>plot</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23890098</td>\n",
       "      <td>Taxi Blues</td>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "      <td>['World cinema', 'Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31186339</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>The nation of Panem consists of a wealthy Capi...</td>\n",
       "      <td>['Action/Adventure', 'Action', 'Science Fictio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20663735</td>\n",
       "      <td>Narasimham</td>\n",
       "      <td>Poovalli Induchoodan  is sentenced for six yea...</td>\n",
       "      <td>['Musical', 'Action', 'Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2231378</td>\n",
       "      <td>The Lemon Drop Kid</td>\n",
       "      <td>The Lemon Drop Kid , a New York City swindler,...</td>\n",
       "      <td>['Comedy']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>595909</td>\n",
       "      <td>A Cry in the Dark</td>\n",
       "      <td>Seventh-day Adventist Church pastor Michael Ch...</td>\n",
       "      <td>['Crime Fiction', 'World cinema', 'Drama']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id          movie_name  \\\n",
       "0  23890098          Taxi Blues   \n",
       "1  31186339    The Hunger Games   \n",
       "2  20663735          Narasimham   \n",
       "3   2231378  The Lemon Drop Kid   \n",
       "4    595909   A Cry in the Dark   \n",
       "\n",
       "                                                plot  \\\n",
       "0  Shlykov, a hard-working taxi driver and Lyosha...   \n",
       "1  The nation of Panem consists of a wealthy Capi...   \n",
       "2  Poovalli Induchoodan  is sentenced for six yea...   \n",
       "3  The Lemon Drop Kid , a New York City swindler,...   \n",
       "4  Seventh-day Adventist Church pastor Michael Ch...   \n",
       "\n",
       "                                               genre  \n",
       "0                          ['World cinema', 'Drama']  \n",
       "1  ['Action/Adventure', 'Action', 'Science Fictio...  \n",
       "2                     ['Musical', 'Action', 'Drama']  \n",
       "3                                         ['Comedy']  \n",
       "4         ['Crime Fiction', 'World cinema', 'Drama']  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting pandas dataframe to pyspark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = spark.createDataFrame(train_data)\n",
    "# training_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data and creating TD-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = Tokenizer(inputCol=\"plot\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(training_df)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "# alternatively, CountVectorizer can also be used to get term frequency vectors\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movie_id=23890098, movie_name='Taxi Blues', plot=\"Shlykov, a hard-working taxi driver and Lyosha, a saxophonist, develop a bizarre love-hate relationship, and despite their prejudices, realize they aren't so different after all.\", genre=\"['World cinema', 'Drama']\", words=['shlykov,', 'a', 'hard-working', 'taxi', 'driver', 'and', 'lyosha,', 'a', 'saxophonist,', 'develop', 'a', 'bizarre', 'love-hate', 'relationship,', 'and', 'despite', 'their', 'prejudices,', 'realize', 'they', \"aren't\", 'so', 'different', 'after', 'all.'], rawFeatures=SparseVector(20, {1: 1.0, 5: 2.0, 6: 1.0, 8: 2.0, 9: 1.0, 10: 4.0, 11: 3.0, 13: 2.0, 15: 3.0, 17: 2.0, 18: 2.0, 19: 2.0}), features=SparseVector(20, {1: 0.0265, 5: 0.0471, 6: 0.0715, 8: 0.0286, 9: 0.0734, 10: 0.0045, 11: 0.2, 13: 0.0283, 15: 0.1344, 17: 0.0414, 18: 0.0773, 19: 0.1171}))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaledData.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|movie_id|          movie_name|                plot|               genre|               words|         rawFeatures|            features|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|23890098|          Taxi Blues|Shlykov, a hard-w...|['World cinema', ...|[shlykov,, a, har...|(20,[1,5,6,8,9,10...|(20,[1,5,6,8,9,10...|\n",
      "|31186339|    The Hunger Games|The nation of Pan...|['Action/Adventur...|[the, nation, of,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|20663735|          Narasimham|Poovalli Induchoo...|['Musical', 'Acti...|[poovalli, induch...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "| 2231378|  The Lemon Drop Kid|The Lemon Drop Ki...|          ['Comedy']|[the, lemon, drop...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|  595909|   A Cry in the Dark|Seventh-day Adven...|['Crime Fiction',...|[seventh-day, adv...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "| 5272176|            End Game|The president is ...|['Action/Adventur...|[the, president, ...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "| 1952976|          Dark Water|{{plot}} The film...|['Thriller', 'Dra...|[{{plot}}, the, f...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|24225279|                Sing|The story begins ...|           ['Drama']|[the, story, begi...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "| 2462689|       Meet John Doe|Infuriated at bei...|['Black-and-white...|[infuriated, at, ...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|20532852|Destination Meatball|A line of people ...|['Animation', 'Sh...|[a, line, of, peo...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|15401493|    Husband for Hire|Lola  attempts to...|          ['Comedy']|[lola, , attempts...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|18188932|         Up and Down|Milan and Goran a...|['Crime Fiction',...|[milan, and, gora...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "| 2940516|Ghost In The Noon...|Bumbling pirate c...|          ['Comedy']|[bumbling, pirate...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "| 1480747|       House Party 2|{{plot}} Followin...|          ['Comedy']|[{{plot}}, follow...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|24448645|Forest of the Dam...|Despite Lucy's re...|          ['Horror']|[despite, lucy's,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|15072401|Charlie Chan's Se...|Alan Colby, heir ...|['Crime Fiction',...|[alan, colby,, he...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "| 4018288|     The Biggest Fan|Debbie's favorite...|           ['Drama']|[debbie's, favori...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "| 4596602|      Ashes to Ashes|Ashes to Ashes is...|['Crime Fiction',...|[ashes, to, ashes...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|15224586|        Green Dragon|The film follows ...|  ['Indie', 'Drama']|[the, film, follo...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|15585766|  The Rats of Tobruk|Three friends are...|           ['Drama']|[three, friends, ...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaledData.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting genre into labels using StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_stringIdx = StringIndexer(inputCol = \"genre\", outputCol = \"label\")\n",
    "fitter = label_stringIdx.fit(rescaledData)\n",
    "rescaledData = fitter.transform(rescaledData)\n",
    "labels = fitter.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Machine Learning model on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data,testing_data) = rescaledData.randomSplit([0.7,0.3], seed=234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting Naive Bayes model on the training data\n",
    "\n",
    "# from pyspark.ml.classification import NaiveBayes\n",
    "# nb = NaiveBayes(smoothing=0.1)\n",
    "# model = nb.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting Random Forest model on the training data\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=20, maxBins=100)\n",
    "model = rf.fit(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/cse587/Project3/randomforest_for_part2\"\n",
    "model.save(\"/home/cse587/Project3/randomforest_for_part2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fitting the obtained model on validation test data\n",
    "predictions = model.transform(training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029308555639158743"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Evaluating the accuracy of predicted labels\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading test data from local using Pandas and converted into pyspark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"/home/cse587/Project3/test.csv\",sep=\",\", header = 0)\n",
    "testing_df = spark.createDataFrame(test_data)\n",
    "# testing_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-processing the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = Tokenizer(inputCol=\"plot\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf])\n",
    "\n",
    "idfModel = pipeline.fit(training_df)\n",
    "test_data2 = idfModel.transform(testing_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movie_id=1335380, movie_name='Exodus', plot='The film is based on the events that happened on the ship Exodus in 1947 as well as events dealing with the founding of the state of Israel in 1948. Nurse Katherine \"Kitty\" Fremont  is an American volunteer at the Karaolos internment camp on Cyprus, where thousands of Jews - Holocaust survivors - are being held by the British, who won\\'t let them go to Palestine. They anxiously wait for the day they will be liberated. Ari Ben Canaan , a Hagannah rebel who previously was a captain in the Jewish Brigade of the British Army in the Second World War, obtains a cargo ship and smuggles 611 Jewish inmates out of the camp for an illegal voyage to Mandate Palestine before being discovered by military authorities. When the British find out that the refugees are in a ship in the harbor of Famagusta, they blockade it. The refugees stage a hunger strike, during which the camp\\'s doctor dies, and Ari threatens to blow up the ship and the refugees. The British relent and allow the Exodus safe passage. Meanwhile, Kitty has grown very fond of Karen Hansen , a young Danish-Jewish girl searching for her father, from whom she was separated during the war. She has taken up the Zionist cause, much to the chagrin of Kitty, who had hoped to take young Karen to America so that she can begin a new life there. During this time, opposition to the partition of Palestine into Arab and Jewish states is heating up, and Karen\\'s young beau Dov Landau  proclaims his desire to join the Irgun, a radical Zionist underground network. Dov goes to an Irgun address, only to get caught in a police trap. After he is freed, he is contacted by members of the Irgun and is interviewed by Ari Ben Canaan\\'s uncle Akiva . Before swearing Dov in, Akiva forces the boy to confess that he was a Sonderkommando in Auschwitz and that he was raped by Nazis. Due to his activities, Akiva has been disowned by Ari\\'s father, Barak , who heads the mainstream Jewish Agency trying to create a Jewish state through political and diplomatic means. He fears that the Irgun will damage his efforts, especially since the British have put a price on Akiva\\'s head. When Dov successfully bombs the King David Hotel in an act of terrorism, leading to dozens of fatalities, Akiva is arrested and sentenced to hang. Meanwhile, Karen\\'s father has been found, but he is ill in hospital in Jerusalem and does not recognize her. Karen has gone to live at Gan Dafna, a fictional Jewish kibbutz near Mount Tabor at which Ari was raised. An actual kibbutz named Dafna is located near the present Lebanese border. Kitty and Ari have fallen in love, but uncle Akiva\\'s imprisonment is an obstacle, and Ari must devise a plan to free the prisoners. Dov Landau, who had managed to elude the arresting soldiers, turns himself in so that he can use his knowledge of explosives to rig the Acre prison and plan an escape route. All goes according to plan; hundreds of prisoners, including Akiva, manage to escape. For the historical incident on which this is based, see Acre Prison break. Akiva is fatally shot by British soldiers while evading a roadblock set up to catch the escaped prisoners. Ari is also badly wounded. He makes his way to Abu Yesha, an Arab village near Gan Dafna, where his lifelong friend, Taha,  is the mukhtar. Kitty is brought there and treats his wound. An independent Israel is now in plain view, but Arab nationals commanded by Mohammad Amin al-Husayni, the Grand Mufti of Jerusalem, plot to attack Gan Dafna and kill its villagers. Ari receives prior warning of this attack from Taha, and he manages to get the younger children of the town out in a mass overnight escape. Karen, ecstatic over the prospect of a new nation, finds Dov  and proclaims her love for him; Dov assures her that they will marry someday. As Karen returns to Gan Dafna, she is ambushed and killed by a gang of Arab militiamen. Dov discovers her lifeless body the following morning. That same day, the body of Taha is found hanging in his village, killed by Arab extremists with a Star of David symbol carved on his body. Karen and Taha are buried together in one grave. At the Jewish burial ceremony, Ari swears on their bodies that someday, Jews and Arabs will live together and share the land in peace, not only in death but also in life. The movie then ends with Ari, Kitty, and a Palmach contingent entering trucks and heading toward battle.', words=['the', 'film', 'is', 'based', 'on', 'the', 'events', 'that', 'happened', 'on', 'the', 'ship', 'exodus', 'in', '1947', 'as', 'well', 'as', 'events', 'dealing', 'with', 'the', 'founding', 'of', 'the', 'state', 'of', 'israel', 'in', '1948.', 'nurse', 'katherine', '\"kitty\"', 'fremont', '', 'is', 'an', 'american', 'volunteer', 'at', 'the', 'karaolos', 'internment', 'camp', 'on', 'cyprus,', 'where', 'thousands', 'of', 'jews', '-', 'holocaust', 'survivors', '-', 'are', 'being', 'held', 'by', 'the', 'british,', 'who', \"won't\", 'let', 'them', 'go', 'to', 'palestine.', 'they', 'anxiously', 'wait', 'for', 'the', 'day', 'they', 'will', 'be', 'liberated.', 'ari', 'ben', 'canaan', ',', 'a', 'hagannah', 'rebel', 'who', 'previously', 'was', 'a', 'captain', 'in', 'the', 'jewish', 'brigade', 'of', 'the', 'british', 'army', 'in', 'the', 'second', 'world', 'war,', 'obtains', 'a', 'cargo', 'ship', 'and', 'smuggles', '611', 'jewish', 'inmates', 'out', 'of', 'the', 'camp', 'for', 'an', 'illegal', 'voyage', 'to', 'mandate', 'palestine', 'before', 'being', 'discovered', 'by', 'military', 'authorities.', 'when', 'the', 'british', 'find', 'out', 'that', 'the', 'refugees', 'are', 'in', 'a', 'ship', 'in', 'the', 'harbor', 'of', 'famagusta,', 'they', 'blockade', 'it.', 'the', 'refugees', 'stage', 'a', 'hunger', 'strike,', 'during', 'which', 'the', \"camp's\", 'doctor', 'dies,', 'and', 'ari', 'threatens', 'to', 'blow', 'up', 'the', 'ship', 'and', 'the', 'refugees.', 'the', 'british', 'relent', 'and', 'allow', 'the', 'exodus', 'safe', 'passage.', 'meanwhile,', 'kitty', 'has', 'grown', 'very', 'fond', 'of', 'karen', 'hansen', ',', 'a', 'young', 'danish-jewish', 'girl', 'searching', 'for', 'her', 'father,', 'from', 'whom', 'she', 'was', 'separated', 'during', 'the', 'war.', 'she', 'has', 'taken', 'up', 'the', 'zionist', 'cause,', 'much', 'to', 'the', 'chagrin', 'of', 'kitty,', 'who', 'had', 'hoped', 'to', 'take', 'young', 'karen', 'to', 'america', 'so', 'that', 'she', 'can', 'begin', 'a', 'new', 'life', 'there.', 'during', 'this', 'time,', 'opposition', 'to', 'the', 'partition', 'of', 'palestine', 'into', 'arab', 'and', 'jewish', 'states', 'is', 'heating', 'up,', 'and', \"karen's\", 'young', 'beau', 'dov', 'landau', '', 'proclaims', 'his', 'desire', 'to', 'join', 'the', 'irgun,', 'a', 'radical', 'zionist', 'underground', 'network.', 'dov', 'goes', 'to', 'an', 'irgun', 'address,', 'only', 'to', 'get', 'caught', 'in', 'a', 'police', 'trap.', 'after', 'he', 'is', 'freed,', 'he', 'is', 'contacted', 'by', 'members', 'of', 'the', 'irgun', 'and', 'is', 'interviewed', 'by', 'ari', 'ben', \"canaan's\", 'uncle', 'akiva', '.', 'before', 'swearing', 'dov', 'in,', 'akiva', 'forces', 'the', 'boy', 'to', 'confess', 'that', 'he', 'was', 'a', 'sonderkommando', 'in', 'auschwitz', 'and', 'that', 'he', 'was', 'raped', 'by', 'nazis.', 'due', 'to', 'his', 'activities,', 'akiva', 'has', 'been', 'disowned', 'by', \"ari's\", 'father,', 'barak', ',', 'who', 'heads', 'the', 'mainstream', 'jewish', 'agency', 'trying', 'to', 'create', 'a', 'jewish', 'state', 'through', 'political', 'and', 'diplomatic', 'means.', 'he', 'fears', 'that', 'the', 'irgun', 'will', 'damage', 'his', 'efforts,', 'especially', 'since', 'the', 'british', 'have', 'put', 'a', 'price', 'on', \"akiva's\", 'head.', 'when', 'dov', 'successfully', 'bombs', 'the', 'king', 'david', 'hotel', 'in', 'an', 'act', 'of', 'terrorism,', 'leading', 'to', 'dozens', 'of', 'fatalities,', 'akiva', 'is', 'arrested', 'and', 'sentenced', 'to', 'hang.', 'meanwhile,', \"karen's\", 'father', 'has', 'been', 'found,', 'but', 'he', 'is', 'ill', 'in', 'hospital', 'in', 'jerusalem', 'and', 'does', 'not', 'recognize', 'her.', 'karen', 'has', 'gone', 'to', 'live', 'at', 'gan', 'dafna,', 'a', 'fictional', 'jewish', 'kibbutz', 'near', 'mount', 'tabor', 'at', 'which', 'ari', 'was', 'raised.', 'an', 'actual', 'kibbutz', 'named', 'dafna', 'is', 'located', 'near', 'the', 'present', 'lebanese', 'border.', 'kitty', 'and', 'ari', 'have', 'fallen', 'in', 'love,', 'but', 'uncle', \"akiva's\", 'imprisonment', 'is', 'an', 'obstacle,', 'and', 'ari', 'must', 'devise', 'a', 'plan', 'to', 'free', 'the', 'prisoners.', 'dov', 'landau,', 'who', 'had', 'managed', 'to', 'elude', 'the', 'arresting', 'soldiers,', 'turns', 'himself', 'in', 'so', 'that', 'he', 'can', 'use', 'his', 'knowledge', 'of', 'explosives', 'to', 'rig', 'the', 'acre', 'prison', 'and', 'plan', 'an', 'escape', 'route.', 'all', 'goes', 'according', 'to', 'plan;', 'hundreds', 'of', 'prisoners,', 'including', 'akiva,', 'manage', 'to', 'escape.', 'for', 'the', 'historical', 'incident', 'on', 'which', 'this', 'is', 'based,', 'see', 'acre', 'prison', 'break.', 'akiva', 'is', 'fatally', 'shot', 'by', 'british', 'soldiers', 'while', 'evading', 'a', 'roadblock', 'set', 'up', 'to', 'catch', 'the', 'escaped', 'prisoners.', 'ari', 'is', 'also', 'badly', 'wounded.', 'he', 'makes', 'his', 'way', 'to', 'abu', 'yesha,', 'an', 'arab', 'village', 'near', 'gan', 'dafna,', 'where', 'his', 'lifelong', 'friend,', 'taha,', '', 'is', 'the', 'mukhtar.', 'kitty', 'is', 'brought', 'there', 'and', 'treats', 'his', 'wound.', 'an', 'independent', 'israel', 'is', 'now', 'in', 'plain', 'view,', 'but', 'arab', 'nationals', 'commanded', 'by', 'mohammad', 'amin', 'al-husayni,', 'the', 'grand', 'mufti', 'of', 'jerusalem,', 'plot', 'to', 'attack', 'gan', 'dafna', 'and', 'kill', 'its', 'villagers.', 'ari', 'receives', 'prior', 'warning', 'of', 'this', 'attack', 'from', 'taha,', 'and', 'he', 'manages', 'to', 'get', 'the', 'younger', 'children', 'of', 'the', 'town', 'out', 'in', 'a', 'mass', 'overnight', 'escape.', 'karen,', 'ecstatic', 'over', 'the', 'prospect', 'of', 'a', 'new', 'nation,', 'finds', 'dov', '', 'and', 'proclaims', 'her', 'love', 'for', 'him;', 'dov', 'assures', 'her', 'that', 'they', 'will', 'marry', 'someday.', 'as', 'karen', 'returns', 'to', 'gan', 'dafna,', 'she', 'is', 'ambushed', 'and', 'killed', 'by', 'a', 'gang', 'of', 'arab', 'militiamen.', 'dov', 'discovers', 'her', 'lifeless', 'body', 'the', 'following', 'morning.', 'that', 'same', 'day,', 'the', 'body', 'of', 'taha', 'is', 'found', 'hanging', 'in', 'his', 'village,', 'killed', 'by', 'arab', 'extremists', 'with', 'a', 'star', 'of', 'david', 'symbol', 'carved', 'on', 'his', 'body.', 'karen', 'and', 'taha', 'are', 'buried', 'together', 'in', 'one', 'grave.', 'at', 'the', 'jewish', 'burial', 'ceremony,', 'ari', 'swears', 'on', 'their', 'bodies', 'that', 'someday,', 'jews', 'and', 'arabs', 'will', 'live', 'together', 'and', 'share', 'the', 'land', 'in', 'peace,', 'not', 'only', 'in', 'death', 'but', 'also', 'in', 'life.', 'the', 'movie', 'then', 'ends', 'with', 'ari,', 'kitty,', 'and', 'a', 'palmach', 'contingent', 'entering', 'trucks', 'and', 'heading', 'toward', 'battle.'], rawFeatures=SparseVector(20, {0: 58.0, 1: 37.0, 2: 32.0, 3: 56.0, 4: 19.0, 5: 47.0, 6: 29.0, 7: 22.0, 8: 62.0, 9: 23.0, 10: 87.0, 11: 21.0, 12: 52.0, 13: 55.0, 14: 28.0, 15: 20.0, 16: 30.0, 17: 42.0, 18: 40.0, 19: 26.0}), features=SparseVector(20, {0: 1.3448, 1: 0.9798, 2: 1.5166, 3: 0.5936, 4: 1.3614, 5: 1.1068, 6: 2.0739, 7: 1.6661, 8: 0.8872, 9: 1.6885, 10: 0.0979, 11: 1.3998, 12: 1.4475, 13: 0.7781, 14: 1.4566, 15: 0.896, 16: 0.8698, 17: 0.8689, 18: 1.5454, 19: 1.5222}))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data2.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the test labels by fitting the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2 = model.transform(test_data2)\n",
    "\n",
    "## converted the predicted labels to its corresponding genre\n",
    "converter = IndexToString(inputCol=\"prediction\", outputCol=\"originalCategory\", labels = labels)\n",
    "test_result = converter.transform(test_pred2)\n",
    "# test_result.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the mapping.csv into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Romance Film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number          name\n",
       "0       0         Drama\n",
       "1       1        Comedy\n",
       "2       2  Romance Film\n",
       "3       3      Thriller\n",
       "4       4        Action"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = pd.read_csv('/home/cse587/Project3/mapping.csv')\n",
    "colnames = ['label','name']\n",
    "mapping.columns =colnames\n",
    "mapping_df = sqlContext.createDataFrame(mapping)\n",
    "# valuelist = [row.name for row in mapping_df.collect()]\n",
    "mapping.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lines):\n",
    "    lines = lines[1:-1].split(', ')\n",
    "    temp=[0]*20\n",
    "    for i in lines:   \n",
    "        for k,v in mapping.iterrows():\n",
    "            if i == ('\\''+ v['name'] +'\\''):\n",
    "                temp[k] = 1\n",
    "                continue\n",
    "    return \" \".join(map(str,temp))\n",
    "\n",
    "# s = \"['Musical', 'Mystery']\"\n",
    "# print(convert(s))\n",
    "converter = udf(convert)\n",
    "test_result = test_result.withColumn(\"predictions\",converter('originalCategory'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "part2_result = test_result.select(\"movie_id\",\"predictions\")\n",
    "# part2_result = part2_result.withColumnRenamed(\"final_prediction\",\"predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the predicted results in .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "part2_result.write.csv('part2_test_result_rf.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|movie_id|         predictions|\n",
      "+--------+--------------------+\n",
      "| 1335380|1 0 0 0 0 0 0 0 0...|\n",
      "+--------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "part2_result.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
