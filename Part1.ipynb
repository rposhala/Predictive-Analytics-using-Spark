{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : Using Term-document matrix for feature engineering and model was built using Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('/home/cse587/spark-2.4.0-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pyspark' from '/home/cse587/spark-2.4.0-bin-hadoop2.7/python/pyspark/__init__.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "\n",
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .appName(\"Assignment3p1\") \\\n",
    "   .config(\"spark.some.config.option\", \"8gb\") \\\n",
    "   .getOrCreate()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlcontext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading necessary libraries for this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "import re\n",
    "# from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "# from pyspark.mllib.regression import LabeledPoint\n",
    "# from pyspark.ml.classification import LogisticRegression, OneVsRest\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.sql.functions import udf, col, lower, regexp_replace\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler, VectorIndexer, IndexToString\n",
    "from pyspark.mllib.linalg import SparseVector, DenseVector\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import RandomForestClassificationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/home/cse587/Project3/train.csv\",sep=\",\", header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the loaded training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_name</th>\n",
       "      <th>plot</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23890098</td>\n",
       "      <td>Taxi Blues</td>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "      <td>['World cinema', 'Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31186339</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>The nation of Panem consists of a wealthy Capi...</td>\n",
       "      <td>['Action/Adventure', 'Action', 'Science Fictio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20663735</td>\n",
       "      <td>Narasimham</td>\n",
       "      <td>Poovalli Induchoodan  is sentenced for six yea...</td>\n",
       "      <td>['Musical', 'Action', 'Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2231378</td>\n",
       "      <td>The Lemon Drop Kid</td>\n",
       "      <td>The Lemon Drop Kid , a New York City swindler,...</td>\n",
       "      <td>['Comedy']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>595909</td>\n",
       "      <td>A Cry in the Dark</td>\n",
       "      <td>Seventh-day Adventist Church pastor Michael Ch...</td>\n",
       "      <td>['Crime Fiction', 'World cinema', 'Drama']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id          movie_name  \\\n",
       "0  23890098          Taxi Blues   \n",
       "1  31186339    The Hunger Games   \n",
       "2  20663735          Narasimham   \n",
       "3   2231378  The Lemon Drop Kid   \n",
       "4    595909   A Cry in the Dark   \n",
       "\n",
       "                                                plot  \\\n",
       "0  Shlykov, a hard-working taxi driver and Lyosha...   \n",
       "1  The nation of Panem consists of a wealthy Capi...   \n",
       "2  Poovalli Induchoodan  is sentenced for six yea...   \n",
       "3  The Lemon Drop Kid , a New York City swindler,...   \n",
       "4  Seventh-day Adventist Church pastor Michael Ch...   \n",
       "\n",
       "                                               genre  \n",
       "0                          ['World cinema', 'Drama']  \n",
       "1  ['Action/Adventure', 'Action', 'Science Fictio...  \n",
       "2                     ['Musical', 'Action', 'Drama']  \n",
       "3                                         ['Comedy']  \n",
       "4         ['Crime Fiction', 'World cinema', 'Drama']  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting pandas dataframe to pyspark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movie_id=23890098, movie_name='Taxi Blues', plot=\"Shlykov, a hard-working taxi driver and Lyosha, a saxophonist, develop a bizarre love-hate relationship, and despite their prejudices, realize they aren't so different after all.\", genre=\"['World cinema', 'Drama']\")]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = spark.createDataFrame(train_data)\n",
    "training_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the pyspark training dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+\n",
      "|movie_id|          movie_name|                plot|               genre|\n",
      "+--------+--------------------+--------------------+--------------------+\n",
      "|23890098|          Taxi Blues|Shlykov, a hard-w...|['World cinema', ...|\n",
      "|31186339|    The Hunger Games|The nation of Pan...|['Action/Adventur...|\n",
      "|20663735|          Narasimham|Poovalli Induchoo...|['Musical', 'Acti...|\n",
      "| 2231378|  The Lemon Drop Kid|The Lemon Drop Ki...|          ['Comedy']|\n",
      "|  595909|   A Cry in the Dark|Seventh-day Adven...|['Crime Fiction',...|\n",
      "| 5272176|            End Game|The president is ...|['Action/Adventur...|\n",
      "| 1952976|          Dark Water|{{plot}} The film...|['Thriller', 'Dra...|\n",
      "|24225279|                Sing|The story begins ...|           ['Drama']|\n",
      "| 2462689|       Meet John Doe|Infuriated at bei...|['Black-and-white...|\n",
      "|20532852|Destination Meatball|A line of people ...|['Animation', 'Sh...|\n",
      "|15401493|    Husband for Hire|Lola  attempts to...|          ['Comedy']|\n",
      "|18188932|         Up and Down|Milan and Goran a...|['Crime Fiction',...|\n",
      "| 2940516|Ghost In The Noon...|Bumbling pirate c...|          ['Comedy']|\n",
      "| 1480747|       House Party 2|{{plot}} Followin...|          ['Comedy']|\n",
      "|24448645|Forest of the Dam...|Despite Lucy's re...|          ['Horror']|\n",
      "|15072401|Charlie Chan's Se...|Alan Colby, heir ...|['Crime Fiction',...|\n",
      "| 4018288|     The Biggest Fan|Debbie's favorite...|           ['Drama']|\n",
      "| 4596602|      Ashes to Ashes|Ashes to Ashes is...|['Crime Fiction',...|\n",
      "|15224586|        Green Dragon|The film follows ...|  ['Indie', 'Drama']|\n",
      "|15585766|  The Rats of Tobruk|Three friends are...|           ['Drama']|\n",
      "+--------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df= training_df.withColumn(\"plot\",F.lower(F.col('plot')))\n",
    "\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"plot\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "data = regexTokenizer.transform(training_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_stopwords =['http','https','amp','rt','t','c','the','despite','working','develop','whence', 'here', 'show', 'were', 'why', \n",
    "            'n’t', 'the', 'whereupon', 'not', 'more', 'how', 'eight', 'indeed', 'i', 'only', 'via', 'nine', \n",
    "            're', 'themselves', 'almost', 'to', 'already', 'front', 'least', 'becomes', 'thereby', 'doing', \n",
    "            'her', 'together', 'be', 'often', 'then', 'quite', 'less', 'many', 'they', 'ourselves', 'take',\n",
    "            'its', 'yours', 'each', 'would', 'may', 'namely', 'do', 'whose', 'whether', 'side', 'both', 'what',\n",
    "            'between', 'toward', 'our', 'whereby', \"'m\", 'formerly', 'myself', 'had', 'really', 'call', 'keep',\n",
    "            \"'re\", 'hereupon', 'can', 'their', 'eleven', '’m', 'even', 'around', 'twenty', 'mostly', 'did', \n",
    "            'at', 'an', 'seems', 'serious', 'against', \"n't\", 'except', 'has', 'five', 'he', 'last', '‘ve', \n",
    "            'because', 'we', 'himself', 'yet', 'something', 'somehow', '‘m', 'towards', 'his', 'six',\n",
    "            'anywhere', 'us', '‘d', 'thru', 'thus', 'which', 'everything', 'become', 'herein', 'one', 'in',\n",
    "            'although', 'sometime', 'give', 'cannot', 'besides', 'across', 'noone', 'ever', 'that', 'over', \n",
    "            'among', 'during', 'however', 'when', 'sometimes', 'still', 'seemed', 'get', \"'ve\", 'him', 'with', \n",
    "            'part', 'beyond', 'everyone', 'same', 'this', 'latterly', 'no', 'regarding', 'elsewhere', 'others', \n",
    "            'moreover', 'else', 'back', 'alone', 'somewhere', 'are', 'will', 'beforehand', 'ten', 'very',\n",
    "            'most', 'three', 'former', '’re', 'otherwise', 'several', 'also', 'whatever', 'am', 'becoming', \n",
    "            'beside', '’s', 'nothing', 'some', 'since', 'thence', 'anyway', 'out', 'up', 'well', 'it',\n",
    "            'various', 'four', 'top', '‘s', 'than', 'under', 'might', 'could', 'by', 'too', 'and',\n",
    "            'whom', '‘ll', 'say', 'therefore', \"'s\", 'other', 'throughout', 'became', 'your', 'put', 'per', \n",
    "            \"'ll\", 'fifteen', 'must', 'before', 'whenever', 'anyone', 'without', 'does', 'was', 'where', \n",
    "            'thereafter', \"'d\", 'another', 'yourselves', 'n‘t', 'see', 'go', 'wherever', 'just', 'seeming', \n",
    "            'hence', 'full', 'whereafter', 'bottom', 'whole', 'own', 'empty', 'due', 'behind', 'while', 'onto', \n",
    "            'wherein', 'off', 'again', 'a', 'two', 'above', 'therein', 'sixty', 'those', 'whereas', 'using', \n",
    "            'latter', 'used', 'my', 'herself', 'hers', 'or', 'neither', 'forty', 'thereupon', 'now', 'after',\n",
    "            'yourself', 'whither', 'rather', 'once', 'from', 'until', 'anything', 'few', 'into', 'such', 'being',\n",
    "            'make', 'mine', 'please', 'along', 'hundred', 'should', 'below', 'third', 'unless', 'upon', 'perhaps',\n",
    "            'ours', 'but', 'never', 'whoever', 'fifty', 'any', 'all', 'nobody', 'there', 'have', 'anyhow', 'of', \n",
    "            'seem', 'down', 'is', 'every', '’ll', 'much', 'none', 'further', 'me', 'who', 'nevertheless', 'about',\n",
    "            'everywhere', 'name', 'enough', '’d', 'next', 'meanwhile', 'though', 'through', 'on', 'first', 'been', \n",
    "            'hereby', 'if', 'move', 'so', 'either', 'amongst', 'for', 'twelve', 'nor', 'she', 'always', 'these', \n",
    "            'as', '’ve', 'amount', '‘re', 'someone', 'afterwards', 'you', 'nowhere', 'itself', 'done', 'hereafter',\n",
    "            'within', 'made', 'ca', 'them']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\" ).setStopWords(extra_stopwords)\n",
    "data = remover.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Term-Document matrix for the modified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\",minDF=120)\n",
    "data1 = countVectors.fit(data)\n",
    "rescaledData = data1.transform(data)\n",
    "#rescaledData.select('features').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|movie_id|          movie_name|                plot|               genre|               words|            filtered|            features|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|23890098|          Taxi Blues|shlykov, a hard-w...|['World cinema', ...|[shlykov, a, hard...|[shlykov, hard, t...|(4969,[8,107,449,...|\n",
      "|31186339|    The Hunger Games|the nation of pan...|['Action/Adventur...|[the, nation, of,...|[nation, panem, c...|(4969,[0,4,5,8,12...|\n",
      "|20663735|          Narasimham|poovalli induchoo...|['Musical', 'Acti...|[poovalli, induch...|[poovalli, induch...|(4969,[0,1,6,8,16...|\n",
      "| 2231378|  The Lemon Drop Kid|the lemon drop ki...|          ['Comedy']|[the, lemon, drop...|[lemon, drop, kid...|(4969,[0,5,7,9,12...|\n",
      "|  595909|   A Cry in the Dark|seventh-day adven...|['Crime Fiction',...|[seventh, day, ad...|[seventh, day, ad...|(4969,[0,6,7,11,1...|\n",
      "| 5272176|            End Game|the president is ...|['Action/Adventur...|[the, president, ...|[president, way, ...|(4969,[0,2,3,9,10...|\n",
      "| 1952976|          Dark Water|{{plot}} the film...|['Thriller', 'Dra...|[plot, the, film,...|[plot, film, open...|(4969,[0,1,2,4,5,...|\n",
      "|24225279|                Sing|the story begins ...|           ['Drama']|[the, story, begi...|[story, begins, h...|(4969,[0,3,5,9,15...|\n",
      "| 2462689|       Meet John Doe|infuriated at bei...|['Black-and-white...|[infuriated, at, ...|[infuriated, told...|(4969,[0,2,7,23,2...|\n",
      "|20532852|Destination Meatball|a line of people ...|['Animation', 'Sh...|[a, line, of, peo...|[line, people, dr...|(4969,[0,23,30,64...|\n",
      "|15401493|    Husband for Hire|lola  attempts to...|          ['Comedy']|[lola, attempts, ...|[lola, attempts, ...|(4969,[0,1,2,5,7,...|\n",
      "|18188932|         Up and Down|milan and goran a...|['Crime Fiction',...|[milan, and, gora...|[milan, goran, cr...|(4969,[11,24,93,9...|\n",
      "| 2940516|Ghost In The Noon...|bumbling pirate c...|          ['Comedy']|[bumbling, pirate...|[bumbling, pirate...|(4969,[0,2,3,12,2...|\n",
      "| 1480747|       House Party 2|{{plot}} followin...|          ['Comedy']|[plot, following,...|[plot, following,...|(4969,[0,1,4,5,7,...|\n",
      "|24448645|Forest of the Dam...|despite lucy's re...|          ['Horror']|[despite, lucy, s...|[lucy, s, reserva...|(4969,[0,6,42,57,...|\n",
      "|15072401|Charlie Chan's Se...|alan colby, heir ...|['Crime Fiction',...|[alan, colby, hei...|[alan, colby, hei...|(4969,[3,11,49,71...|\n",
      "| 4018288|     The Biggest Fan|debbie's favorite...|           ['Drama']|[debbie, s, favor...|[debbie, s, favor...|(4969,[0,5,19,20,...|\n",
      "| 4596602|      Ashes to Ashes|ashes to ashes is...|['Crime Fiction',...|[ashes, to, ashes...|[ashes, ashes, se...|(4969,[0,2,6,12,2...|\n",
      "|15224586|        Green Dragon|the film follows ...|  ['Indie', 'Drama']|[the, film, follo...|[film, follows, e...|(4969,[0,2,8,12,1...|\n",
      "|15585766|  The Rats of Tobruk|three friends are...|           ['Drama']|[three, friends, ...|[friends, droving...|(4969,[0,7,8,35,3...|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rescaledData.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting genre into labels using StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_stringIdx = StringIndexer(inputCol = \"genre\", outputCol = \"label\")\n",
    "fitter = label_stringIdx.fit(rescaledData)\n",
    "rescaledData = fitter.transform(rescaledData)\n",
    "# rescaledData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Storing the labels\n",
    "labels = fitter.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Machine Learning model on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## splitting training and testing data\n",
    "(training_data,testing_data) = rescaledData.randomSplit([0.7,0.3], seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting Naive Bayes model on the training data\n",
    "\n",
    "# from pyspark.ml.classification import NaiveBayes\n",
    "# nb = NaiveBayes(smoothing=0.1)\n",
    "# model = nb.fit(training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting Random Forest model on the training data\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=20, maxBins=100)\n",
    "model = rf.fit(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"/home/cse587/Project3/randomforest_for_part1\"\n",
    "model.save(\"/home/cse587/Project3/randomforest_for_part1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassificationModel\n",
    "savedmodel = RandomForestClassificationModel.load(path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fitting the obtained model on validation test data\n",
    "predictions = savedmodel.transform(testing_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02669043003965693"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Evaluating the accuracy of predicted labels\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|movie_id|prediction|\n",
      "+--------+----------+\n",
      "|    3217|       0.0|\n",
      "|    3837|       0.0|\n",
      "|    3947|       0.0|\n",
      "|    4729|       0.0|\n",
      "|    5313|       0.0|\n",
      "|    9429|       0.0|\n",
      "|    9835|       0.0|\n",
      "|    9979|       0.0|\n",
      "|   11992|       0.0|\n",
      "|   11998|       0.0|\n",
      "|   12001|       0.0|\n",
      "|   12004|       0.0|\n",
      "|   13154|       0.0|\n",
      "|   17920|       0.0|\n",
      "|   19701|       0.0|\n",
      "|   20669|       0.0|\n",
      "|   21174|       0.0|\n",
      "|   22727|       0.0|\n",
      "|   22751|       0.0|\n",
      "|   23255|       0.0|\n",
      "+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('movie_id','prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting predicted labels to its corresponding predicted genre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = IndexToString(inputCol=\"prediction\", outputCol=\"originalCategory\", labels = labels)\n",
    "converted = converter.transform(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------+--------------------+--------------------+----------+--------------------+\n",
      "|movie_id|          movie_name|                plot|               genre|               words|            filtered|            features| label|       rawPrediction|         probability|prediction|    originalCategory|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------+--------------------+--------------------+----------+--------------------+\n",
      "|    3217|    Army of Darkness|after being pulle...|['Action/Adventur...|[after, being, pu...|[pulled, time, po...|(4969,[0,3,5,6,13...| 639.0|[-1377.3557989146...|[1.17345889846608...|      40.0|['Comedy', 'Horror']|\n",
      "|    3837|     Blazing Saddles|in the american o...|          ['Comedy']|[in, the, america...|[american, old, w...|(4969,[0,2,7,20,2...|   1.0|[-2081.7498502198...|[5.14092481451537...|       1.0|          ['Comedy']|\n",
      "|    3947|         Blue Velvet|jeffrey beaumont ...|['Crime Fiction',...|[jeffrey, beaumon...|[jeffrey, beaumon...|(4969,[0,1,2,3,4,...| 112.0|[-2911.4268879186...|[5.47867255551710...|      17.0|['Thriller', 'Hor...|\n",
      "|    4729|      Batman & Robin| in gotham city, ...|['Crime Fiction',...|[in, gotham, city...|[gotham, city, ba...|(4969,[0,4,7,12,1...| 379.0|[-1533.9361021348...|[3.65550917546187...|       1.0|          ['Comedy']|\n",
      "|    5313|Crouching Tiger, ...|li mu bai  is an ...|['Drama', 'Advent...|[li, mu, bai, is,...|[li, mu, bai, acc...|(4969,[0,3,4,6,8,...| 438.0|[-2277.0249780001...|[9.59644435493936...|      37.0|       ['Adventure']|\n",
      "|    9429|  Young and Innocent| christine clay ,...|['Black-and-white...|[christine, clay,...|[christine, clay,...|(4969,[0,1,3,5,12...| 582.0|[-1481.2542640787...|[0.99420967124457...|       0.0|           ['Drama']|\n",
      "|    9835|Escape from New York|in a dystopian 19...|['Crime Fiction',...|[in, a, dystopian...|[dystopian, 1988,...|(4969,[0,3,4,5,6,...|1927.0|[-2549.4619282591...|[1.03497468724129...|     302.0|['Adventure', 'Ac...|\n",
      "|    9979|      Eyes Wide Shut|dr. bill harford ...|['Drama', 'Thrill...|[dr, bill, harfor...|[dr, bill, harfor...|(4969,[0,1,2,3,4,...| 300.0|[-5152.6171358471...|[5.47385286277517...|       2.0|          ['Horror']|\n",
      "|   11992|Godzilla vs. the ...|after yata  is lo...|['Science Fiction...|[after, yata, is,...|[yata, lost, sea,...|(4969,[0,20,23,25...| 215.0|[-783.73581523959...|[6.09417683725832...|      35.0| ['Science Fiction']|\n",
      "|   11998|Godzilla vs. Megalon|for years, seatop...|['Science Fiction...|[for, years, seat...|[years, seatopia,...|(4969,[0,5,9,14,2...|  29.0|[-1417.6783774874...|[3.27134352424706...|      35.0| ['Science Fiction']|\n",
      "|   12001|Terror of Mechago...|continuing after ...|['Science Fiction...|[continuing, afte...|[continuing, end,...|(4969,[0,1,4,7,8,...| 215.0|[-1188.4062216778...|[6.55040404989279...|     114.0|['Action', 'Scien...|\n",
      "|   12004|            Godzilla| when a japanese ...|['Black-and-white...|[when, a, japanes...|[japanese, fishin...|(4969,[0,4,5,6,7,...|1555.0|[-2562.4761658085...|[1.36562695081349...|      35.0| ['Science Fiction']|\n",
      "|   13154|     Glen or Glenda?| the first part o...|['Indie', 'Comedy...|[the, first, part...|[film, begins, na...|(4969,[0,2,4,6,29...|  25.0|[-801.96189262610...|[5.01417273670902...|       3.0|      ['Short Film']|\n",
      "|   17920|       Life of Brian|brian cohen is bo...|          ['Comedy']|[brian, cohen, is...|[brian, cohen, bo...|(4969,[0,2,3,5,6,...|   1.0|[-1549.5880215982...|[0.99999999840503...|       0.0|           ['Drama']|\n",
      "|   19701|Monty Python and ...|monty python and ...|['Action/Adventur...|[monty, python, a...|[monty, python, h...|(4969,[0,2,14,16,...| 823.0|[-1819.1238415362...|[3.64871825401729...|      37.0|       ['Adventure']|\n",
      "|   20669|  My Neighbor Totoro|{{right}} in 1958...|['Animation', 'Ad...|[right, in, 1958,...|[right, 1958, kus...|(4969,[0,1,5,7,9,...|2398.0|[-1976.5525316165...|[7.61133492355546...|       2.0|          ['Horror']|\n",
      "|   21174| Nanook of the North|  the documentary...| ['Black-and-white']|[the, documentary...|[documentary, fol...|(4969,[11,22,106,...|  24.0|[-127.30602099755...|[0.69290791767818...|       0.0|           ['Drama']|\n",
      "|   22727|      Otaku no Video|the main characte...|['Animation', 'Co...|[the, main, chara...|[main, character,...|(4969,[0,5,6,12,1...| 705.0|[-1933.1594066956...|[7.18202472191795...|       3.0|      ['Short Film']|\n",
      "|   22751|        Original Sin|original sin is s...|['Romance Film', ...|[original, sin, i...|[original, sin, s...|(4969,[0,3,4,7,8,...| 450.0|[-2148.7139331476...|[4.39909986027221...|       9.0|['Comedy', 'Roman...|\n",
      "|   23255|      Paths of Glory|the film begins w...|['Black-and-white...|[the, film, begin...|[film, begins, vo...|(4969,[0,2,3,4,6,...|   8.0|[-2793.3917863512...|[0.99987918258190...|       0.0|           ['Drama']|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------+--------------------+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "converted.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading test data from local using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data = pd.read_csv(\"/home/cse587/Project3/test.csv\",sep=\",\", header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating testing dataframe in pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df = spark.createDataFrame(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-processing the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df= testing_df.withColumn(\"plot\",F.lower(F.col('plot')))\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"plot\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\" ).setStopWords(extra_stopwords)\n",
    "\n",
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\",minDF=120)\n",
    "pipeline = Pipeline(stages=[regexTokenizer, remover, countVectors])\n",
    "\n",
    "data = pipeline.fit(training_df)\n",
    "test_data = data.transform(testing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+--------------------+--------------------+--------------------+\n",
      "|movie_id|movie_name|                plot|               words|            filtered|            features|\n",
      "+--------+----------+--------------------+--------------------+--------------------+--------------------+\n",
      "| 1335380|    Exodus|the film is based...|[the, film, is, b...|[film, based, eve...|(4969,[0,1,2,5,6,...|\n",
      "+--------+----------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the test labels by fitting the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|movie_id|prediction|\n",
      "+--------+----------+\n",
      "| 1335380|       0.0|\n",
      "|29062594|       0.0|\n",
      "| 9252321|       0.0|\n",
      "|13455076|       0.0|\n",
      "|24165951|       0.0|\n",
      "| 1925869|       0.0|\n",
      "|10799612|       0.0|\n",
      "|28238240|       0.0|\n",
      "|17124781|       0.0|\n",
      "|28207941|       0.0|\n",
      "|19174305|       0.0|\n",
      "|18392317|       0.0|\n",
      "|34420857|       0.0|\n",
      "| 4039635|       0.0|\n",
      "| 8034072|       0.0|\n",
      "| 4016437|       0.0|\n",
      "| 1520023|       2.0|\n",
      "|24589422|       0.0|\n",
      "|35068740|       0.0|\n",
      "|21132951|       0.0|\n",
      "+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred.select('movie_id','prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the original genre back from predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+----------------+\n",
      "|movie_id|          movie_name|                plot|               words|            filtered|            features|       rawPrediction|         probability|prediction|originalCategory|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+----------------+\n",
      "| 1335380|              Exodus|the film is based...|[the, film, is, b...|[film, based, eve...|(4969,[0,1,2,5,6,...|[1.63401036216089...|[0.08170051810804...|       0.0|       ['Drama']|\n",
      "|29062594|A la salida nos v...|a group of teenag...|[a, group, of, te...|[group, teenagers...|(4969,[5,6,44,57,...|[2.65486293857844...|[0.13274314692892...|       0.0|       ['Drama']|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "converter = IndexToString(inputCol=\"prediction\", outputCol=\"originalCategory\", labels = labels)\n",
    "test_result = converter.transform(test_pred)\n",
    "test_result.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the mapping.csv into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Romance Film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label          name\n",
       "0      0         Drama\n",
       "1      1        Comedy\n",
       "2      2  Romance Film\n",
       "3      3      Thriller\n",
       "4      4        Action"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = pd.read_csv('/home/cse587/Project3/mapping.csv')\n",
    "colnames = ['label','name']\n",
    "mapping.columns =colnames\n",
    "mapping_df = spark.createDataFrame(mapping)\n",
    "\n",
    "mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lines):\n",
    "    lines = lines[1:-1].split(', ')\n",
    "    temp=[0]*20\n",
    "    for i in lines:   \n",
    "        for k,v in mapping.iterrows():\n",
    "            if i == ('\\''+ v['name'] +'\\''):\n",
    "                temp[k] = 1\n",
    "                continue\n",
    "    return \" \".join(map(str,temp))\n",
    "\n",
    "converter = udf(convert)\n",
    "test_result = test_result.withColumn(\"predictions\",converter('originalCategory'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+----------------+--------------------+\n",
      "|movie_id|movie_name|                plot|               words|            filtered|            features|       rawPrediction|         probability|prediction|originalCategory|    final_prediction|\n",
      "+--------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+----------------+--------------------+\n",
      "| 1335380|    Exodus|the film is based...|[the, film, is, b...|[film, based, eve...|(4969,[0,1,2,5,6,...|[-2135.1100553928...|[0.99907098773483...|       0.0|       ['Drama']|1 0 0 0 0 0 0 0 0...|\n",
      "+--------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+----------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_result.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1_result = test_result.select(\"movie_id\",\"predictions\")\n",
    "# part1_result = part1_result.withColumnRenamed(\"final_prediction\",\"predictions\")\n",
    "# part1_result.show(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the predicted results in .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1_result.write.csv('part1_test_result_rf.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movie_id=1335380, predictions='1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part1_result.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
