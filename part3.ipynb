{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 : Using Word2vec for feature engineering and model was built using Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('/home/cse587/spark-2.4.0-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "\n",
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .appName(\"Assignment3p3\") \\\n",
    "   .config(\"spark.some.config.option\", \"8gb\") \\\n",
    "   .getOrCreate()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlcontext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading necessary libraries for this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "import re\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import numpy as np\n",
    "from pyspark.ml.classification import LogisticRegression, OneVsRest\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.sql.functions import udf, col, lower, regexp_replace\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler, VectorIndexer, IndexToString\n",
    "from pyspark.ml.feature import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = pd.read_csv(\"/home/cse587/Project3/train.csv\",sep=\",\", header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_name</th>\n",
       "      <th>plot</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23890098</td>\n",
       "      <td>Taxi Blues</td>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "      <td>['World cinema', 'Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31186339</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>The nation of Panem consists of a wealthy Capi...</td>\n",
       "      <td>['Action/Adventure', 'Action', 'Science Fictio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20663735</td>\n",
       "      <td>Narasimham</td>\n",
       "      <td>Poovalli Induchoodan  is sentenced for six yea...</td>\n",
       "      <td>['Musical', 'Action', 'Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2231378</td>\n",
       "      <td>The Lemon Drop Kid</td>\n",
       "      <td>The Lemon Drop Kid , a New York City swindler,...</td>\n",
       "      <td>['Comedy']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>595909</td>\n",
       "      <td>A Cry in the Dark</td>\n",
       "      <td>Seventh-day Adventist Church pastor Michael Ch...</td>\n",
       "      <td>['Crime Fiction', 'World cinema', 'Drama']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id          movie_name  \\\n",
       "0  23890098          Taxi Blues   \n",
       "1  31186339    The Hunger Games   \n",
       "2  20663735          Narasimham   \n",
       "3   2231378  The Lemon Drop Kid   \n",
       "4    595909   A Cry in the Dark   \n",
       "\n",
       "                                                plot  \\\n",
       "0  Shlykov, a hard-working taxi driver and Lyosha...   \n",
       "1  The nation of Panem consists of a wealthy Capi...   \n",
       "2  Poovalli Induchoodan  is sentenced for six yea...   \n",
       "3  The Lemon Drop Kid , a New York City swindler,...   \n",
       "4  Seventh-day Adventist Church pastor Michael Ch...   \n",
       "\n",
       "                                               genre  \n",
       "0                          ['World cinema', 'Drama']  \n",
       "1  ['Action/Adventure', 'Action', 'Science Fictio...  \n",
       "2                     ['Musical', 'Action', 'Drama']  \n",
       "3                                         ['Comedy']  \n",
       "4         ['Crime Fiction', 'World cinema', 'Drama']  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting pandas dataframe to pyspark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = spark.createDataFrame(train_data)\n",
    "# training_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"plot\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "\n",
    "wordsData = regexTokenizer.transform(training_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+--------------------+--------------------+\n",
      "|movie_id|movie_name|                plot|               genre|               words|\n",
      "+--------+----------+--------------------+--------------------+--------------------+\n",
      "|23890098|Taxi Blues|Shlykov, a hard-w...|['World cinema', ...|[shlykov, a, hard...|\n",
      "+--------+----------+--------------------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wordsData.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and transforming Word2vec to the modified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(vectorSize = 100, minCount = 5, inputCol = 'words', outputCol = 'features')\n",
    "model = word2vec.fit(wordsData)\n",
    "word2vec_data = model.transform(wordsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movie_id=23890098, movie_name='Taxi Blues', plot=\"Shlykov, a hard-working taxi driver and Lyosha, a saxophonist, develop a bizarre love-hate relationship, and despite their prejudices, realize they aren't so different after all.\", genre=\"['World cinema', 'Drama']\", words=['shlykov', 'a', 'hard', 'working', 'taxi', 'driver', 'and', 'lyosha', 'a', 'saxophonist', 'develop', 'a', 'bizarre', 'love', 'hate', 'relationship', 'and', 'despite', 'their', 'prejudices', 'realize', 'they', 'aren', 't', 'so', 'different', 'after', 'all'], result=DenseVector([-0.0093, -0.0276, 0.0352, -0.0737, 0.0013, -0.0538, 0.0286, 0.0399, 0.0213, 0.0282, 0.0882, -0.0535, 0.0088, 0.0018, -0.0203, 0.006, -0.011, -0.0338, 0.0361, -0.1029, 0.0324, -0.0044, 0.0606, 0.0576, 0.0389, 0.0091, -0.0722, 0.0204, 0.0166, 0.0138, -0.0051, 0.0088, 0.025, -0.0762, 0.1317, 0.0337, 0.0803, 0.0133, -0.0832, 0.0594, 0.044, 0.0837, -0.0601, -0.1051, 0.0032, -0.0801, -0.0658, -0.1003, 0.0344, -0.0654, 0.0645, 0.039, -0.0146, 0.0413, -0.0059, 0.0953, 0.0462, -0.0708, 0.0736, -0.1296, -0.0033, -0.0131, 0.0761, -0.073, -0.0102, 0.0169, -0.0301, -0.0385, 0.0715, 0.0505, -0.0722, 0.0364, -0.0074, -0.0686, 0.0347, -0.0903, 0.0804, 0.0509, -0.0432, -0.0576, 0.0388, 0.0422, 0.0172, 0.07, -0.0622, -0.0967, 0.0108, -0.09, -0.0647, 0.0843, -0.0699, 0.0041, -0.0088, -0.0326, -0.1058, 0.1107, 0.0008, -0.0701, 0.0735, 0.0601]))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting genre into labels using StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_stringIdx = StringIndexer(inputCol = \"genre\", outputCol = \"label\")\n",
    "fitter = label_stringIdx.fit(word2vec_data)\n",
    "rescaledData = fitter.transform(word2vec_data)\n",
    "labels = fitter.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Machine Learning model on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data,testing_data) = rescaledData.randomSplit([0.7,0.3], seed=4234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting Random Forest model on the training data\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=20, maxBins=100)\n",
    "model = rf.fit(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/home/cse587/Project3/randomforest_for_part3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fitting the obtained model on validation test data\n",
    "predictions = model.transform(training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046310743304631356"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Evaluating the accuracy of predicted labels\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading test data from local using Pandas and converted into pyspark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data = pd.read_csv(\"/home/cse587/Project3/test.csv\",sep=\",\", header = 0)\n",
    "testing_df = spark.createDataFrame(test_data)\n",
    "# testing_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-processing the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"plot\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "word2vec = Word2Vec(vectorSize = 100, minCount = 5, inputCol = 'words', outputCol = 'features')\n",
    "\n",
    "pipeline = Pipeline(stages=[regexTokenizer, word2vec])\n",
    "\n",
    "idfModel = pipeline.fit(training_df)\n",
    "test_data2 = idfModel.transform(testing_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+----------------+\n",
      "|movie_id|movie_name|                plot|               words|            features|       rawPrediction|         probability|prediction|originalCategory|\n",
      "+--------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+----------------+\n",
      "| 1335380|    Exodus|The film is based...|[the, film, is, b...|[0.03900388203832...|[2.29609556569081...|[0.11480477828454...|       0.0|       ['Drama']|\n",
      "+--------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_result.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the test labels by fitting the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2 = model.transform(test_data2)\n",
    "\n",
    "converter = IndexToString(inputCol=\"prediction\", outputCol=\"originalCategory\", labels = labels)\n",
    "test_result = converter.transform(test_pred2)\n",
    "# test_result.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the mapping.csv into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Romance Film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number          name\n",
       "0       0         Drama\n",
       "1       1        Comedy\n",
       "2       2  Romance Film\n",
       "3       3      Thriller\n",
       "4       4        Action"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = pd.read_csv('/home/cse587/Project3/mapping.csv')\n",
    "colnames = ['label','name']\n",
    "mapping.columns =colnames\n",
    "mapping_df = sqlContext.createDataFrame(mapping)\n",
    "# valuelist = [row.name for row in mapping_df.collect()]\n",
    "mapping.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lines):\n",
    "    lines = lines[1:-1].split(', ')\n",
    "    temp=[0]*20\n",
    "    for i in lines:   \n",
    "        for k,v in mapping.iterrows():\n",
    "            if i == ('\\''+ v['name'] +'\\''):\n",
    "                temp[k] = 1\n",
    "                continue\n",
    "    return \" \".join(map(str,temp))\n",
    "\n",
    "converter = udf(convert)\n",
    "test_result = test_result.withColumn(\"predictions\",converter('originalCategory'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "part2_result = test_result.select(\"movie_id\",\"predictions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the predicted results in .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "part2_result.write.csv('part3_test_result_rf.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
